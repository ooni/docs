---
title: System Architecture
slug: backend/architecture
sidebar:
    order: 2
---

The backend infrastructure performs multiple functions:

  * Provide APIs for data consumers

  * Instruct probes on what measurements to perform

  * Receive measurements from probes, process them and store them in the database

* Upload new measurements to a bucket on [S3 data bucket](#s3-data-bucket)&thinsp;💡

  * Fetch data from external sources e.g. fingerprints from a GitHub repository

## Main data flows
  This diagram represent the main flow of measurement data.

  The rectangles represent processes. The ellipses represent data at rest:
  as files on disk, files on S3 or records in database tables.

  ![Diagram](https://kroki.io/blockdiag/svg/eNrFlD1PwzAQhvf-CstdSTOwFYEEKkgMSJUQU4Uqf5wbU8c2_kCVEP-d2E3SlrZjQzbfG_t9fL47qgxbc0lW6HuEOAgSVVj6ilhAt8iZqDlwajY3IzR3hoJHC2aUcY2Ix0JA8-ErVDkQKVKFYP20LFcyVJFOmKlLY7QsKWFr0LzghsUadCBBGl1SZWhZE6k7fXmgT2o-ttkTvzf2jxvb-ILbB0j2QmQZv16jD2-0wmjR4YNS0nq4IF92LIRULWSisMYHRvSgHK1nCzF72KYCBfof6QiEKuhJBPHBklANDtMZ7_Nw6dfoM0KEQVGSbbG1zRhvTSkTDg6fKOYLYtRAfHSQYkXsEDLQU5urgYG6J0oQ_YAp7hC-nz9Pt2vkwX1J1vRXFnagaXVUXv3el91V253d_MDpvmfP3y-Q_rA-Vzm0GzSn3Q4fuN3RDYVj8aBZj7v3vMdJ1D9__fwCHdgDSg==)

<!--
  blockdiag {
    default_shape = roundedbox;
    Probes [color = "#ffeeee", href = "@@probes"];
    Explorer [color = "#eeeeff"];
    "S3 jsonl" [shape = ellipse, href = "@@jsonl-files"];
    "S3 postcan" [shape = ellipse, href = "@@postcans"];
    "DB jsonl tbl" [shape = ellipse, href = "@@jsonl-table"];
    "DB fastpath tbl" [shape = ellipse, href = "@@fastpath-table"];
    "disk queue" [shape = ellipse, href = "@@disk-queue"];
    "Uploader" [color = "#eeeeff", href = "@@measurement-uploader"];
    "Fastpath" [color = "#eeeeff", href = "@@fastpath"];

    Probes -> "API: Probe services" -> "Fastpath" -> "DB fastpath tbl" -> "API: Measurements" -> "Explorer";
    "API: Probe services" -> "disk queue" -> "API: uploader" -> "S3 jsonl" -> "API: Measurements";
    "Uploader" -> "S3 postcan";
    "Uploader" -> "DB jsonl tbl";
    "DB jsonl tbl" -> "API: Measurements";
    "disk queue" -> "API: Measurements";
  }
-->

Ellipses represent data; rectangles represent processes. Click on the
image and then click on each shape to see related documentation.

Probes submit measurements to the API with a POST at the following path:
<https://api.ooni.io/apidocs/#/default/post_report__report_id_> The
measurement is optionally decompressed if zstd compression is detected.
It is then parsed and added with a unique ID and saved to disk. Very
little validation is done at this time in order to ensure that all
incoming measurements are accepted.

Measurements are enqueued on disk using one file per measurement. On
hourly intervals they are batched together, compressed and uploaded to
S3 by the [Measurement uploader](#measurement-uploader)&thinsp;⚙. The batching is
performed to allow efficient compression. See the
[dedicated subchapter](#measurement-uploader)&thinsp;⚙ for details.

The measurement is also sent to the [Fastpath](#fastpath)&thinsp;⚙. The
Fastpath runs as a dedicated daemon with a pool of workers. It
calculates scoring for the measurement and writes a record in the
fastpath table. Each measurement is processed individually in real time.
See the [dedicated subchapter](#fastpath)&thinsp;⚙ below.

The disk queue is also used by the API to access recent measurements
that have not been uploaded to S3 yet. See the
[measurement API](#getting-measurement-bodies)&thinsp;🐝 for details.


## Reproducibility
The measurement processing pipeline is meant to generate outputs that
can be equally generated by 3rd parties like external researchers and
other organizations.

This is meant to keep OONI accountable and as a proof that we do not
arbitrarily delete or alter measurements and that we score them as
accessible/anomaly/confirmed/failure in a predictable and transparent
way.

> **important**
> The only exceptions were due to privacy breaches that required removal
> of the affected measurements from the [S3 data bucket](#s3-data-bucket)&thinsp;💡
> bucket.

  As such, the backend infrastructure is
  [FOSS](https://en.wikipedia.org/wiki/Free_and_open-source_software) and
  can be deployed by 3rd parties. We encourage researchers to replicate
  our findings.

  Incoming measurements are minimally altered by the
  [Measurement uploader](#measurement-uploader)&thinsp;⚙ and uploaded to S3.


## Supply chain management

The backend implements software supply chain management by installing components and libraries from the Debian Stable archive.

This provides the following benefits:

 * Receiving targeted security updates from the OS without introducing breaking changes.
 * Protection against supply chain attacks.
 * Reproducible deployment for internal use (e.g. testbeds and new backend hosts) and for external researchers.

> **warning**
> [ClickHouse](#clickhouse)&thinsp;⚙ is installed from a 3rd party archive and receives limited security support. As a mitigation an LTS version is used yet the support time is 1 year.

The backend received a security assessment from Cure53 <https://cure53.de/> in 2022.

Low-criticality hosts e.g. the monitoring stack also have components installed from 3rd party archives.